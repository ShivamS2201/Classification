{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Does This thing really work? Let's see.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Does This thing really work?', \"Let's see.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['does', 'this', 'thing', 'really', 'work', '?', 'let', \"'s\", 'see', '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = word_tokenize(sample_text.lower())\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words = [w for w in words if not w in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thing', 'really', 'work', '?', 'let', \"'s\", 'see', '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stop + punctuations\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words = [w for w in words if not w in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thing', 'really', 'work', 'let', \"'s\", 'see']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porter Stemmer\n",
    "\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_words =['play', 'playing', 'player', 'played']\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = [ps.stem(i) for i in stem_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['play', 'play', 'player', 'play']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import state_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\SHIVAM.DESKTOP-\n",
      "[nltk_data]     MC4MCE1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = state_union.raw('2006-GWBush.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33411"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pos_tag(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PRESIDENT', 'NNP'),\n",
       " ('GEORGE', 'NNP'),\n",
       " ('W.', 'NNP'),\n",
       " ('BUSH', 'NNP'),\n",
       " (\"'S\", 'POS'),\n",
       " ('ADDRESS', 'NNP'),\n",
       " ('BEFORE', 'IN'),\n",
       " ('A', 'NNP'),\n",
       " ('JOINT', 'NNP'),\n",
       " ('SESSION', 'NNP'),\n",
       " ('OF', 'IN'),\n",
       " ('THE', 'NNP'),\n",
       " ('CONGRESS', 'NNP'),\n",
       " ('ON', 'NNP'),\n",
       " ('THE', 'NNP'),\n",
       " ('STATE', 'NNP'),\n",
       " ('OF', 'IN'),\n",
       " ('THE', 'NNP'),\n",
       " ('UNION', 'NNP'),\n",
       " ('January', 'NNP'),\n",
       " ('31', 'CD'),\n",
       " (',', ','),\n",
       " ('2006', 'CD'),\n",
       " ('THE', 'NNP'),\n",
       " ('PRESIDENT', 'NNP'),\n",
       " (':', ':'),\n",
       " ('Thank', 'NNP'),\n",
       " ('you', 'PRP'),\n",
       " ('all', 'DT'),\n",
       " ('.', '.'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Speaker', 'NNP'),\n",
       " (',', ','),\n",
       " ('Vice', 'NNP'),\n",
       " ('President', 'NNP'),\n",
       " ('Cheney', 'NNP'),\n",
       " (',', ','),\n",
       " ('members', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('Congress', 'NNP'),\n",
       " (',', ','),\n",
       " ('members', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Supreme', 'NNP'),\n",
       " ('Court', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('diplomatic', 'JJ'),\n",
       " ('corps', 'NN'),\n",
       " (',', ','),\n",
       " ('distinguished', 'JJ'),\n",
       " ('guests', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('fellow', 'JJ'),\n",
       " ('citizens', 'NNS'),\n",
       " (':', ':'),\n",
       " ('Today', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('nation', 'NN'),\n",
       " ('lost', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('beloved', 'VBN'),\n",
       " (',', ','),\n",
       " ('graceful', 'JJ'),\n",
       " (',', ','),\n",
       " ('courageous', 'JJ'),\n",
       " ('woman', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('called', 'VBD'),\n",
       " ('America', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('its', 'PRP$'),\n",
       " ('founding', 'NN'),\n",
       " ('ideals', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('carried', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('noble', 'JJ'),\n",
       " ('dream', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Tonight', 'NN'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('comforted', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('hope', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('glad', 'JJ'),\n",
       " ('reunion', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('husband', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('was', 'VBD'),\n",
       " ('taken', 'VBN'),\n",
       " ('so', 'RB'),\n",
       " ('long', 'RB'),\n",
       " ('ago', 'RB'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('grateful', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('life', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Coretta', 'NNP'),\n",
       " ('Scott', 'NNP'),\n",
       " ('King', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('(', '('),\n",
       " ('Applause', 'NNP'),\n",
       " ('.', '.'),\n",
       " (')', ')'),\n",
       " ('President', 'NNP'),\n",
       " ('George', 'NNP'),\n",
       " ('W.', 'NNP'),\n",
       " ('Bush', 'NNP'),\n",
       " ('reacts', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('applause', 'VB'),\n",
       " ('during', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('State', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Union', 'NNP'),\n",
       " ('Address', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Capitol', 'NNP'),\n",
       " (',', ','),\n",
       " ('Tuesday', 'NNP'),\n",
       " (',', ','),\n",
       " ('Jan.', 'NNP'),\n",
       " ('31', 'CD'),\n",
       " (',', ','),\n",
       " ('2006', 'CD'),\n",
       " ('.', '.'),\n",
       " ('White', 'NNP'),\n",
       " ('House', 'NNP'),\n",
       " ('photo', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('Eric', 'NNP'),\n",
       " ('DraperEvery', 'NNP'),\n",
       " ('time', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('invited', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('this', 'DT'),\n",
       " ('rostrum', 'NN'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('humbled', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('privilege', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('mindful', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('history', 'NN'),\n",
       " ('we', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('seen', 'VBN'),\n",
       " ('together', 'RB'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('gathered', 'VBN'),\n",
       " ('under', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('Capitol', 'NNP'),\n",
       " ('dome', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('moments', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('national', 'JJ'),\n",
       " ('mourning', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('national', 'JJ'),\n",
       " ('achievement', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('served', 'VBN'),\n",
       " ('America', 'NNP'),\n",
       " ('through', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('consequential', 'JJ'),\n",
       " ('periods', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('history', 'NN'),\n",
       " ('--', ':'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('my', 'PRP$'),\n",
       " ('honor', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('serve', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('system', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('two', 'CD'),\n",
       " ('parties', 'NNS'),\n",
       " (',', ','),\n",
       " ('two', 'CD'),\n",
       " ('chambers', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('two', 'CD'),\n",
       " ('elected', 'JJ'),\n",
       " ('branches', 'NNS'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('will', 'MD'),\n",
       " ('always', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('differences', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('debate', 'NN'),\n",
       " ('.', '.'),\n",
       " ('But', 'CC'),\n",
       " ('even', 'RB'),\n",
       " ('tough', 'JJ'),\n",
       " ('debates', 'NNS'),\n",
       " ('can', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('conducted', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('civil', 'JJ'),\n",
       " ('tone', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('our', 'PRP$'),\n",
       " ('differences', 'NNS'),\n",
       " ('can', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('allowed', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('harden', 'VB'),\n",
       " ('into', 'IN'),\n",
       " ('anger', 'NN'),\n",
       " ('.', '.'),\n",
       " ('To', 'TO'),\n",
       " ('confront', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('issues', 'NNS'),\n",
       " ('before', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('must', 'MD'),\n",
       " ('act', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('spirit', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('goodwill', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('respect', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('another', 'DT'),\n",
       " ('--', ':'),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('do', 'VB'),\n",
       " ('my', 'PRP$'),\n",
       " ('part', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Tonight', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('state', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('Union', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('strong', 'JJ'),\n",
       " ('--', ':'),\n",
       " ('and', 'CC'),\n",
       " ('together', 'RB'),\n",
       " ('we', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('make', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('stronger', 'JJR'),\n",
       " ('.', '.'),\n",
       " ('(', '('),\n",
       " ('Applause', 'NNP'),\n",
       " ('.', '.'),\n",
       " (')', ')'),\n",
       " ('In', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('decisive', 'JJ'),\n",
       " ('year', 'NN'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('make', 'VB'),\n",
       " ('choices', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('determine', 'VBP'),\n",
       " ('both', 'DT'),\n",
       " ('the', 'DT'),\n",
       " ('future', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('character', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('country', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('choose', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('act', 'VB'),\n",
       " ('confidently', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('pursuing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('enemies', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('freedom', 'NN'),\n",
       " ('--', ':'),\n",
       " ('or', 'CC'),\n",
       " ('retreat', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('duties', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('hope', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('easier', 'JJR'),\n",
       " ('life', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('choose', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('build', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('prosperity', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('leading', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('economy', 'NN'),\n",
       " ('--', ':'),\n",
       " ('or', 'CC'),\n",
       " ('shut', 'VB'),\n",
       " ('ourselves', 'PRP'),\n",
       " ('off', 'RP'),\n",
       " ('from', 'IN'),\n",
       " ('trade', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('opportunity', 'NN'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('complex', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('challenging', 'JJ'),\n",
       " ('time', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('road', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('isolationism', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('protectionism', 'NN'),\n",
       " ('may', 'MD'),\n",
       " ('seem', 'VB'),\n",
       " ('broad', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('inviting', 'NN'),\n",
       " ('--', ':'),\n",
       " ('yet', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('ends', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('danger', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('decline', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('only', 'JJ'),\n",
       " ('way', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('protect', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('people', 'NNS'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('only', 'JJ'),\n",
       " ('way', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('secure', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('peace', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('only', 'JJ'),\n",
       " ('way', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('control', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('destiny', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('by', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('leadership', 'NN'),\n",
       " ('--', ':'),\n",
       " ('so', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('United', 'NNP'),\n",
       " ('States', 'NNPS'),\n",
       " ('of', 'IN'),\n",
       " ('America', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('continue', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('lead', 'VB'),\n",
       " ('.', '.'),\n",
       " ('(', '('),\n",
       " ('Applause', 'NNP'),\n",
       " ('.', '.'),\n",
       " (')', ')'),\n",
       " ('Abroad', 'NN'),\n",
       " (',', ','),\n",
       " ('our', 'PRP$'),\n",
       " ('nation', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('committed', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('an', 'DT'),\n",
       " ('historic', 'JJ'),\n",
       " (',', ','),\n",
       " ('long-term', 'JJ'),\n",
       " ('goal', 'NN'),\n",
       " ('--', ':'),\n",
       " ('we', 'PRP'),\n",
       " ('seek', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('end', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('tyranny', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('world', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Some', 'DT'),\n",
       " ('dismiss', 'VBP'),\n",
       " ('that', 'DT'),\n",
       " ('goal', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('misguided', 'JJ'),\n",
       " ('idealism', 'NN'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('reality', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('future', 'JJ'),\n",
       " ('security', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('America', 'NNP'),\n",
       " ('depends', 'VBZ'),\n",
       " ('on', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('On', 'IN'),\n",
       " ('September', 'NNP'),\n",
       " ('the', 'DT'),\n",
       " ('11th', 'CD'),\n",
       " (',', ','),\n",
       " ('2001', 'CD'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('found', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('problems', 'NNS'),\n",
       " ('originating', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('failed', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('oppressive', 'JJ'),\n",
       " ('state', 'NN'),\n",
       " ('7,000', 'CD'),\n",
       " ('miles', 'NNS'),\n",
       " ('away', 'RB'),\n",
       " ('could', 'MD'),\n",
       " ('bring', 'VB'),\n",
       " ('murder', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('destruction', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('our', 'PRP$'),\n",
       " ('country', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Dictatorships', 'NNP'),\n",
       " ('shelter', 'NN'),\n",
       " ('terrorists', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('feed', 'VB'),\n",
       " ('resentment', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('radicalism', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('seek', 'JJ'),\n",
       " ('weapons', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('mass', 'NN'),\n",
       " ('destruction', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Democracies', 'NNS'),\n",
       " ('replace', 'VB'),\n",
       " ('resentment', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('hope', 'NN'),\n",
       " (',', ','),\n",
       " ('respect', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('rights', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('citizens', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('their', 'PRP$'),\n",
       " ('neighbors', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('fight', 'NN'),\n",
       " ('against', 'IN'),\n",
       " ('terror', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Every', 'DT'),\n",
       " ('step', 'NN'),\n",
       " ('toward', 'IN'),\n",
       " ('freedom', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('makes', 'VBZ'),\n",
       " ('our', 'PRP$'),\n",
       " ('country', 'NN'),\n",
       " ('safer', 'NN'),\n",
       " ('--', ':'),\n",
       " ('so', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('act', 'VB'),\n",
       " ('boldly', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('freedom', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('cause', 'NN'),\n",
       " ('.', '.'),\n",
       " ('(', '('),\n",
       " ('Applause', 'NNP'),\n",
       " ('.', '.'),\n",
       " (')', ')'),\n",
       " ('Far', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('being', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('hopeless', 'NN'),\n",
       " ('dream', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('advance', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('freedom', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('story', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('time', 'NN'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('1945', 'CD'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('were', 'VBD'),\n",
       " ('about', 'RB'),\n",
       " ('two', 'CD'),\n",
       " ('dozen', 'NN'),\n",
       " ('lonely', 'RB'),\n",
       " ('democracies', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Today', 'NN'),\n",
       " (',', ','),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('122', 'CD'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " (\"'re\", 'VBP'),\n",
       " ('writing', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('chapter', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('story', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('self-government', 'JJ'),\n",
       " ('--', ':'),\n",
       " ('with', 'IN'),\n",
       " ('women', 'NNS'),\n",
       " ('lining', 'VBG'),\n",
       " ('up', 'RP'),\n",
       " ('to', 'TO'),\n",
       " ('vote', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('Afghanistan', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('millions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('Iraqis', 'NNP'),\n",
       " ('marking', 'VBG'),\n",
       " ('their', 'PRP$'),\n",
       " ('liberty', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('purple', 'JJ'),\n",
       " ('ink', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('men', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('women', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('Lebanon', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('Egypt', 'NNP'),\n",
       " ('debating', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('rights', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('individuals', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('necessity', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('freedom', 'NN'),\n",
       " ('.', '.'),\n",
       " ('At', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('start', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('2006', 'CD'),\n",
       " (',', ','),\n",
       " ('more', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('half', 'PDT'),\n",
       " ('the', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('world', 'NN'),\n",
       " ('live', 'VBP'),\n",
       " ('in', 'IN'),\n",
       " ('democratic', 'JJ'),\n",
       " ('nations', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('forget', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('other', 'JJ'),\n",
       " ('half', 'NN'),\n",
       " ('--', ':'),\n",
       " ('in', 'IN'),\n",
       " ('places', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('Syria', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Burma', 'NNP'),\n",
       " (',', ','),\n",
       " ('Zimbabwe', 'NNP'),\n",
       " (',', ','),\n",
       " ('North', 'NNP'),\n",
       " ('Korea', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('Iran', 'NNP'),\n",
       " ('--', ':'),\n",
       " ('because', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('demands', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('justice', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('peace', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('world', 'NN'),\n",
       " (',', ','),\n",
       " ('require', 'VBP'),\n",
       " ('their', 'PRP$'),\n",
       " ('freedom', 'NN'),\n",
       " (',', ','),\n",
       " ('as', 'RB'),\n",
       " ('well', 'RB'),\n",
       " ('.', '.'),\n",
       " ('(', '('),\n",
       " ('Applause', 'NNP'),\n",
       " ('.', '.'),\n",
       " (')', ')'),\n",
       " ('President', 'NNP'),\n",
       " ('George', 'NNP'),\n",
       " ('W.', 'NNP'),\n",
       " ('Bush', 'NNP'),\n",
       " ('delivers', 'VBZ'),\n",
       " ('his', 'PRP$'),\n",
       " ('State', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Union', 'NNP'),\n",
       " ('Address', 'NNP'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Capitol', 'NNP'),\n",
       " (',', ','),\n",
       " ('Tuesday', 'NNP'),\n",
       " (',', ','),\n",
       " ('Jan.', 'NNP'),\n",
       " ('31', 'CD'),\n",
       " (',', ','),\n",
       " ('2006', 'CD'),\n",
       " ('.', '.'),\n",
       " ('White', 'NNP'),\n",
       " ('House', 'NNP'),\n",
       " ('photo', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('Eric', 'NNP'),\n",
       " ('Draper', 'NNP'),\n",
       " ('No', 'NNP'),\n",
       " ('one', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('deny', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('success', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('freedom', 'NN'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('some', 'DT'),\n",
       " ('men', 'NNS'),\n",
       " ('rage', 'VB'),\n",
       " ('and', 'CC'),\n",
       " ('fight', 'VB'),\n",
       " ('against', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('main', 'JJ'),\n",
       " ('sources', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('reaction', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('opposition', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('radical', 'JJ'),\n",
       " ('Islam', 'NNP'),\n",
       " ('--', ':'),\n",
       " ('the', 'DT'),\n",
       " ('perversion', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('noble', 'JJ'),\n",
       " ('faith', 'NN'),\n",
       " ('into', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('ideology', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('terror', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('death', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Terrorists', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('bin', 'NN'),\n",
       " ('Laden', 'NNP'),\n",
       " ('are', 'VBP'),\n",
       " ('serious', 'JJ'),\n",
       " ('about', 'IN'),\n",
       " ('mass', 'NN'),\n",
       " ('murder', 'NN'),\n",
       " ('--', ':'),\n",
       " ('and', 'CC'),\n",
       " ('all', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('must', 'MD'),\n",
       " ('take', 'VB'),\n",
       " ('their', 'PRP$'),\n",
       " ('declared', 'JJ'),\n",
       " ('intentions', 'NNS'),\n",
       " ('seriously', 'RB'),\n",
       " ('.', '.'),\n",
       " ('They', 'PRP'),\n",
       " ('seek', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('impose', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('heartless', 'NN'),\n",
       " ('system', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('totalitarian', 'JJ'),\n",
       " ('control', 'NN'),\n",
       " ('throughout', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Middle', 'NNP'),\n",
       " ('East', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('arm', 'NN'),\n",
       " ('themselves', 'PRP'),\n",
       " ('with', 'IN'),\n",
       " ('weapons', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('mass', 'NN'),\n",
       " ('murder', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Their', 'PRP$'),\n",
       " ('aim', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('seize', 'VB'),\n",
       " ('power', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Iraq', 'NNP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('use', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('safe', 'JJ'),\n",
       " ('haven', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('launch', 'VB'),\n",
       " ('attacks', 'NNS'),\n",
       " ('against', 'IN'),\n",
       " ('America', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Lacking', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('military', 'JJ'),\n",
       " ('strength', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('challenge', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('directly', 'RB'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('terrorists', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('chosen', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('weapon', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('fear', 'NN'),\n",
       " ('.', '.'),\n",
       " ('When', 'WRB'),\n",
       " ('they', 'PRP'),\n",
       " ('murder', 'VBP'),\n",
       " ('children', 'NNS'),\n",
       " ('at', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('school', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('Beslan', 'NNP'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('blow', 'VB'),\n",
       " ('up', 'RP'),\n",
       " ('commuters', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('London', 'NNP'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('behead', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('bound', 'NN'),\n",
       " ('captive', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('terrorists', 'NNS'),\n",
       " ('hope', 'VBP'),\n",
       " ('these', 'DT'),\n",
       " ('horrors', 'NNS'),\n",
       " ('will', 'MD'),\n",
       " ('break', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('will', 'MD'),\n",
       " (',', ','),\n",
       " ('allowing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('violent', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('inherit', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('Earth', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('But', 'CC'),\n",
       " ('they', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('miscalculated', 'VBN'),\n",
       " (':', ':'),\n",
       " ('We', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('our', 'PRP$'),\n",
       " ('freedom', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('fight', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('keep', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('(', '('),\n",
       " ('Applause', 'NNP'),\n",
       " ('.', '.'),\n",
       " (')', ')'),\n",
       " ('In', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('testing', 'VBG'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('find', 'VB'),\n",
       " ('security', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('abandoning', 'VBG'),\n",
       " ('our', 'PRP$'),\n",
       " ('commitments', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('retreating', 'VBG'),\n",
       " ('within', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ...]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "POS tag list:\n",
    "\n",
    "CC coordinating conjunction\n",
    "CD cardinal digit\n",
    "DT determiner\n",
    "EX existential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "FW foreign word\n",
    "IN preposition/subordinating conjunction\n",
    "JJ adjective 'big'\n",
    "JJR adjective, comparative 'bigger'\n",
    "JJS adjective, superlative 'biggest'\n",
    "LS list marker 1)\n",
    "MD modal could, will\n",
    "NN noun, singular 'desk'\n",
    "NNS noun plural 'desks'\n",
    "NNP proper noun, singular 'Harrison'\n",
    "NNPS proper noun, plural 'Americans'\n",
    "PDT predeterminer 'all the kids'\n",
    "POS possessive ending parent's\n",
    "PRP personal pronoun I, he, she\n",
    "PRP$ possessive pronoun my, his, hers\n",
    "RB adverb very, silently,\n",
    "RBR adverb, comparative better\n",
    "RBS adverb, superlative best\n",
    "RP particle give up\n",
    "TO to go 'to' the store.\n",
    "UH interjection errrrrrrrm\n",
    "VB verb, base form take\n",
    "VBD verb, past tense took\n",
    "VBG verb, gerund/present participle taking\n",
    "VBN verb, past participle taken\n",
    "VBP verb, sing. present, non-3d take\n",
    "VBZ verb, 3rd person sing. present takes\n",
    "WDT wh-determiner which\n",
    "WP wh-pronoun who, what\n",
    "WP$ possessive wh-pronoun whose\n",
    "WRB wh-abverb where, when\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2=  \"raj went for a walk.\"\n",
    "pos_2 = pos_tag(word_tokenize(text_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('raj', 'NN'),\n",
       " ('went', 'VBD'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('walk', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('painting', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_3 = \"This painting is beautiful.\" \n",
    "pos_3 = pos_tag(word_tokenize(text_3))\n",
    "pos_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1/nltk_data'\n    - 'D:\\\\ML\\\\nltk_data'\n    - 'D:\\\\ML\\\\share\\\\nltk_data'\n    - 'D:\\\\ML\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1/nltk_data'\n    - 'D:\\\\ML\\\\nltk_data'\n    - 'D:\\\\ML\\\\share\\\\nltk_data'\n    - 'D:\\\\ML\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-e4b647a47735>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nice'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"a\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1/nltk_data'\n    - 'D:\\\\ML\\\\nltk_data'\n    - 'D:\\\\ML\\\\share\\\\nltk_data'\n    - 'D:\\\\ML\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "lemmatizer.lemmatize('nice', pos = \"a\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1/nltk_data'\n    - 'D:\\\\ML\\\\nltk_data'\n    - 'D:\\\\ML\\\\share\\\\nltk_data'\n    - 'D:\\\\ML\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1/nltk_data'\n    - 'D:\\\\ML\\\\nltk_data'\n    - 'D:\\\\ML\\\\share\\\\nltk_data'\n    - 'D:\\\\ML\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-9064707256a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'happier'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"a\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1/nltk_data'\n    - 'D:\\\\ML\\\\nltk_data'\n    - 'D:\\\\ML\\\\share\\\\nltk_data'\n    - 'D:\\\\ML\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "lemmatizer.lemmatize('happier', pos = \"a\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1/nltk_data'\n    - 'D:\\\\ML\\\\nltk_data'\n    - 'D:\\\\ML\\\\share\\\\nltk_data'\n    - 'D:\\\\ML\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1/nltk_data'\n    - 'D:\\\\ML\\\\nltk_data'\n    - 'D:\\\\ML\\\\share\\\\nltk_data'\n    - 'D:\\\\ML\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-5a08441fda37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'painting'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"n\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1/nltk_data'\n    - 'D:\\\\ML\\\\nltk_data'\n    - 'D:\\\\ML\\\\share\\\\nltk_data'\n    - 'D:\\\\ML\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHIVAM.DESKTOP-MC4MCE1\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "lemmatizer.lemmatize('painting', pos = \"n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paint'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('painting', pos = \"v\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
